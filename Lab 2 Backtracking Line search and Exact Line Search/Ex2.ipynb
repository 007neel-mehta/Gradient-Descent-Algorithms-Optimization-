{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20i190008_IE684_Lab2_Ex2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rEwWOvwtfxfs",
        "bBwIUDBGw3lL",
        "y8xCxvXm2piO",
        "M7GGaTFOWTvC",
        "ylgxDhRKXECQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEwWOvwtfxfs"
      },
      "source": [
        "# ***Part 1:*** *General code and definitions*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk6vPIxeL2xh"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdgyvsHuMEG7"
      },
      "source": [
        "# evaluationg evalf and evalf\r\n",
        "\r\n",
        "def evalf(N,x):\r\n",
        "  assert type(N) is int and N >0\r\n",
        "  assert type(x) is np.ndarray and len(x) == N\r\n",
        "  x = x.reshape((N,1))\r\n",
        "  a = np.array([10**-i for i in range(1,N+1)]).reshape((1,N))\r\n",
        "  b = np.arange(1,N+1).reshape((N,1))\r\n",
        "  f = np.dot(a,(x-b)**2)\r\n",
        "  return float(f)\r\n",
        "\r\n",
        "def evalg(N,x):\r\n",
        "  assert type(N) is int and N >0\r\n",
        "  assert type(x) is np.ndarray and len(x) == N\r\n",
        "  c = np.arange(1,N+1)\r\n",
        "  d = np.array([10**i for i in range(1,N+1)])\r\n",
        "  g = 2*(x - c) / d\r\n",
        "  return g\r\n",
        "\r\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP0ANftQnEdC"
      },
      "source": [
        "The equation $h(x)$ can be written as follows siince its in quadratic form :\r\n",
        "\r\n",
        " \\begin{array}{l}\r\n",
        "\r\n",
        "\r\n",
        " \\\\ \\\\  \\\\\r\n",
        "\r\n",
        "h( X) \\ =\\ \\sum ^{n}_{i=1}\\frac{1}{10^{i}}( x_{i} -i)^{2}\\\\\r\n",
        "\\\\\r\n",
        "=\\sum ^{n}_{i=1}\\frac{1}{10^{i}}\\left( x^{2}_{i} +i^{2} -2x_{i} .i\\right)\\\\\r\n",
        "=\\begin{bmatrix}\r\n",
        "x_{1} & \\dotsc  & ... & x_{n}\r\n",
        "\\end{bmatrix}\\begin{bmatrix}\r\n",
        "\\frac{1}{10} &  &  & \\\\\r\n",
        " & \\frac{1}{10^{2}} &  & \\\\\r\n",
        " &  & \\ddots  & \\\\\r\n",
        " &  &  & \\frac{1}{10^{n}}\r\n",
        "\\end{bmatrix}\\begin{bmatrix}\r\n",
        "x_{1}\\\\\r\n",
        "x_{2}\\\\\r\n",
        "\\vdots \\\\\r\n",
        "x_{n}\r\n",
        "\\end{bmatrix} \\ -\\ \\begin{bmatrix}\r\n",
        "\\frac{2}{10} & \\frac{4}{10^{2}} & ... & \\frac{2n}{10^{n}}\r\n",
        "\\end{bmatrix}\\begin{bmatrix}\r\n",
        "x_{1}\\\\\r\n",
        "x_{2}\\\\\r\n",
        "\\vdots \\\\\r\n",
        "x_{n}\r\n",
        "\\end{bmatrix} \\ +\\left(\\frac{1}{10} +\\frac{2^{2}}{10^{2}} +\\dotsc +\\frac{n^{2}}{10^{n}} \\ \\right)\r\n",
        "\r\n",
        "\\\\ =x^TA \\ x - b^T x + C\r\n",
        "\\end{array}\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMN8jhIFNds5"
      },
      "source": [
        "# defining a function to compute step length using the closed form expression \r\n",
        "\r\n",
        "def compute_steplength_exact(N, g, A):\r\n",
        "  assert type(g) is np.ndarray and len(g) == N\r\n",
        "  assert type(A) is np.ndarray and A.shape[0] == N and  A.shape[1] == N\r\n",
        "\r\n",
        "  step_length = (np.dot(g.T, g)) / (np.matmul(np.matmul(g.T,2*A ),g))\r\n",
        "  return step_length\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#defining a function to compute step_length from backtracking\r\n",
        "\r\n",
        "def compute_steplength_backtracking(N, x, gradf, alpha_start, rho, gamma):\r\n",
        "  assert type(x) is np.ndarray and len(gradf) == N\r\n",
        "  assert type(gradf) is np.ndarray and len(gradf) == N\r\n",
        "  \r\n",
        "  alpha = alpha_start\r\n",
        "  p = -gradf\r\n",
        "\r\n",
        "  while (evalf(N,x + alpha*p) > (evalf(N,x) + gamma * alpha * np.dot(gradf.T, p)) ):\r\n",
        "    alpha = alpha*rho\r\n",
        "  \r\n",
        "  return alpha\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "EXACT_LINE_SEARCH = 1\r\n",
        "BACKTRACKING_LINE_SEARCH = 2\r\n",
        "CONSTANT_STEP_LENGTH = 3\r\n",
        "\r\n",
        "\r\n",
        "def find_minimizer(N,start_x, tol, line_search_type, *args):\r\n",
        "  #Input: start_x is a numpy array of size 2, tol denotes the tolerance and is a positive float value\r\n",
        "  assert type(start_x) is np.ndarray and len(start_x) == N #do not allow arbitrary arguments \r\n",
        "  assert type(tol) is float and tol>=0 \r\n",
        "  # construct a suitable A matrix for the quadratic function \r\n",
        "\r\n",
        "  A =np.zeros((N,N))\r\n",
        "\r\n",
        "  for i in range(N):\r\n",
        "    A[i][i] = 10**(-i-1)\r\n",
        "    \r\n",
        "  x = start_x\r\n",
        "  g_x = evalg(N,x)\r\n",
        "\r\n",
        "  #initialization for backtracking line search\r\n",
        "  if(line_search_type == BACKTRACKING_LINE_SEARCH):\r\n",
        "    alpha_start = args[0]\r\n",
        "    rho = args[1]\r\n",
        "    gamma = args[2]\r\n",
        "    #print('Params for Backtracking LS: alpha start:', alpha_start, 'rho:', rho,' gamma:', gamma)\r\n",
        "\r\n",
        "  k = 0\r\n",
        "  #print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\r\n",
        "\r\n",
        "  while (np.linalg.norm(g_x) > tol):\r\n",
        "     #continue as long as the norm of gradient is not close to zero upto a tolerance tol\r\n",
        "  \r\n",
        "    if line_search_type == EXACT_LINE_SEARCH:\r\n",
        "      step_length = compute_steplength_exact(N,g_x, A) #call the new function you wrote to compute the steplength\r\n",
        "      \r\n",
        "      #raise ValueError('EXACT LINE SEARCH NOT YET IMPLEMENTED')\r\n",
        "\r\n",
        "    elif line_search_type == BACKTRACKING_LINE_SEARCH:\r\n",
        "      step_length = compute_steplength_backtracking(N,x,g_x, alpha_start,rho, gamma) #call the new function you wrote to compute the steplength\r\n",
        "      \r\n",
        "      #raise ValueError('BACKTRACKING LINE SEARCH NOT YET IMPLEMENTED')\r\n",
        "\r\n",
        "    #elif line_search_type == CONSTANT_STEP_LENGTH: #do a gradient descent with constant step length\r\n",
        "      #step_length = 0.1\r\n",
        "\r\n",
        "    else:  \r\n",
        "      raise ValueError('Line search type unknown. Please check!')\r\n",
        "    \r\n",
        "    #implement the gradient descent steps here   \r\n",
        "    x = np.subtract(x, np.multiply(step_length,g_x)) #update x = x - step_length*g_x\r\n",
        "    k += 1 #increment iteration\r\n",
        "    g_x = evalg(N,x) #compute gradient at new point\r\n",
        "\r\n",
        "    #print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\r\n",
        "  return x,k \r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "  \r\n",
        "\r\n"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBwIUDBGw3lL"
      },
      "source": [
        "# ***Part 2 :*** *Evaluating the minimzer and the minimum value using ELS and BLS*\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sxv--trRl0i",
        "outputId": "ebd02fe2-7fc3-45c6-d538-8d8b7c3bc2a9"
      },
      "source": [
        "x_start = np.array([5,5,5])\r\n",
        "my_tol = 10e-9\r\n",
        "alpha = 1\r\n",
        "rho = 0.5\r\n",
        "gamma = 0.5\r\n",
        "\r\n",
        "x_els, k_els = find_minimizer(3,x_start,my_tol,EXACT_LINE_SEARCH)\r\n",
        "x_bls, k_bls = find_minimizer(3,x_start,my_tol,BACKTRACKING_LINE_SEARCH,alpha,rho,gamma)\r\n",
        "\r\n",
        "print('Using Exact Line Search Method - ')\r\n",
        "print('Minimizer : ', x_els)\r\n",
        "print('The value at the minimizer :', evalf(3,x_els))\r\n",
        "\r\n",
        "print('\\n')\r\n",
        "\r\n",
        "print('Using Backtracking Line Search Method - ')\r\n",
        "print('Minimizer : ', x_bls)\r\n",
        "print('The value at the minimizer :', evalf(3,x_bls))\r\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Exact Line Search Method - \n",
            "Minimizer :  [0.99999998 2.         3.00000449]\n",
            "The value at the minimizer : 2.015852775005177e-14\n",
            "\n",
            "\n",
            "Using Backtracking Line Search Method - \n",
            "Minimizer :  [1.         2.         3.00000499]\n",
            "The value at the minimizer : 2.4915872700821508e-14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8xCxvXm2piO"
      },
      "source": [
        "# ***Part 3 :*** *Comparing ELS to BLS using the following parameters*\r\n",
        "\r\n",
        "$x^0 = (0.01, 0.1 , 1)$\r\n",
        "\r\n",
        "$\\tau = 10^{-9}$\r\n",
        "\r\n",
        "$\\alpha ^{0}  =1$\r\n",
        "\r\n",
        "$\\rho  = 0.5$\r\n",
        "\r\n",
        "$\\gamma  = 0.5$\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxB9hNCOr3B8",
        "outputId": "169fe411-252d-49ad-8eef-e5fbc71fd080"
      },
      "source": [
        "x_start = np.array([0.01, 0.1, 1])\r\n",
        "my_tol = 10e-9\r\n",
        "alpha = 1\r\n",
        "rho = 0.5\r\n",
        "gamma = 0.5\r\n",
        "\r\n",
        "x_els, k_els = find_minimizer(3,x_start,my_tol,EXACT_LINE_SEARCH)\r\n",
        "x_bls, k_bls = find_minimizer(3,x_start,my_tol,BACKTRACKING_LINE_SEARCH,alpha,rho,gamma)\r\n",
        "\r\n",
        "print('Using Exact Line Search Method - ')\r\n",
        "print('No. of iterations performed : ', k_els)\r\n",
        "\r\n",
        "\r\n",
        "print('\\n')\r\n",
        "\r\n",
        "print('Using Backtracking Line Search Method - ')\r\n",
        "print('No. of iterations performed : ', k_bls)\r\n",
        "\r\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Exact Line Search Method - \n",
            "No. of iterations performed :  209\n",
            "\n",
            "\n",
            "Using Backtracking Line Search Method - \n",
            "No. of iterations performed :  6444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCKyYkj_VsTS"
      },
      "source": [
        "***Remarks :*** *We observe that as the number of iteration in ELS is very less. That is the answer converge very fast in this alogithm than baktracking which takes a lot of iterations. Given the form of the function, ELS finds the optimum steplength where backtracking iterate again and again to find the solution*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7GGaTFOWTvC"
      },
      "source": [
        "# ***Part 4 :*** *Comparing ELS to BLS using the following parameters*\r\n",
        "\r\n",
        "$x^0 = (0.001,0.01, 0.1 , 1)$\r\n",
        "\r\n",
        "$\\tau = 10^{-9}$\r\n",
        "\r\n",
        "$\\alpha ^{0}  =1$\r\n",
        "\r\n",
        "$\\rho  = 0.5$\r\n",
        "\r\n",
        "$\\gamma  = 0.5$\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBB-fXCi6rvG",
        "outputId": "381f3d8d-6c24-47c2-fcf2-627080407088"
      },
      "source": [
        "x_start = np.array([0.001,0.01, 0.1, 1])\r\n",
        "my_tol = 10e-9\r\n",
        "alpha = 1\r\n",
        "rho = 0.5\r\n",
        "gamma = 0.5\r\n",
        "\r\n",
        "x_els, k_els = find_minimizer(4,x_start,my_tol,EXACT_LINE_SEARCH)\r\n",
        "x_bls, k_bls = find_minimizer(4,x_start,my_tol,BACKTRACKING_LINE_SEARCH,alpha,rho,gamma)\r\n",
        "\r\n",
        "print('Using Exact Line Search Method - ')\r\n",
        "print('No. of iterations performed : ', k_els)\r\n",
        "\r\n",
        "\r\n",
        "print('\\n')\r\n",
        "\r\n",
        "print('Using Backtracking Line Search Method - ')\r\n",
        "print('No. of iterations performed : ', k_bls)\r\n",
        "\r\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Exact Line Search Method - \n",
            "No. of iterations performed :  1861\n",
            "\n",
            "\n",
            "Using Backtracking Line Search Method - \n",
            "No. of iterations performed :  55005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZmpPJPoWwyJ"
      },
      "source": [
        "***Remarks :*** *Yes, the similar observation holds when N=4. And we observe that again els algorith outperforms BLS in the number of iterationn done to find the optimal answer.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylgxDhRKXECQ"
      },
      "source": [
        "# ***Part 5 :*** *For when N>4*\r\n",
        "\r\n",
        "\r\n",
        "***Remarks :*** *Since we have already mentioned it above. The reason ELS ourtperforms better than BLS is that the close form solution for the optimal value of the step length exist in the ELS. And that value exist because we have chosen a quadrratic function where such a solution is possible by solving an optimizationn problem for eta.* ***Even for N>4, if we choose this function, ELS will still outperform BLS and as the dimension of the problem increase we hope to see even  bigger difference in the number of iterations performed.***\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J97z7L_Q-L0Y"
      },
      "source": [
        ""
      ],
      "execution_count": 85,
      "outputs": []
    }
  ]
}